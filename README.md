# Machine learning paper summaries
Summaries of machine learning papers, mostly on NLU / NLP / Deep learning

## To read

- Generating Long Sequences with Sparse Transformers (2019) [[Paper](https://arxiv.org/abs/1904.10509)]
    - Rewon Child, Scott Gray, Alec Radford, Ilya Sutskever

## 2020  

- Cross-lingual transfer learning for spoken language understanding (2019) [[Summary](./summaries/x-lingual-tl-ds.pdf)] [[Paper](https://arxiv.org/abs/1904.01825)]
    - Quynh Ngoc Thi Do, Judith Gaspers

- Curriculum learning (2009) [[Summary](./summaries/curriculum-learning.pdf)] [[Paper](https://ronan.collobert.com/pub/matos/2009_curriculum_icml.pdf)] 
    - Yoshua Bengio, Jerome Louradour, Ronan Collobert, Jason Weston

- Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates (2018) [[Summary](./summaries/subword-regularization.pdf)] [[Paper](https://arxiv.org/pdf/1804.10959.pdf)]
    - Taku Kudo

- Neural Machine Translation of Rare Words with Subword Units (2015) [[Summary](./summaries/nmt-rare-words-subwords.pdf)] [[Paper](https://arxiv.org/abs/1508.07909)]
    - Rico Sennrich, Barry Haddow, Alexandra Birch

- Multi-Source Cross-Lingual Model Transfer: Learning What to Share (2019) [[Summary](./summaries/learning-what-to-share.pdf)] [[Paper](https://arxiv.org/abs/1810.03552)]
    - Xilun Chen, Ahmed Hassan Awadallah, Hany Hassan, Wei Wang, Claire Cardie

- Specializing Word Embeddings (for Parsing) by Information Bottleneck (2019) [[Summary](./summaries/specializing-word-embeddings-vib.pdf)] [[Paper](https://arxiv.org/abs/1910.00163)]
    - Xiang Lisa Li, Jason Eisner

- Deep Neural Network Compression with Single and Multiple Level Quantization (2018) [[Summary](./summaries/dnn-compression-slq-mlq.pdf)] [[Paper](https://arxiv.org/abs/1803.03289)] 
    - Yuhui Xu, Yongzhuang Wang, Aojun Zhou, Weiyao Lin, Hongkai Xiong

- SLIDE : In Defense of Smart Algorithms over Hardware Acceleration for Large-Scale Deep Learning Systems (2019) [[Summary](./summaries/slide-defense.pdf)] [[Paper](https://arxiv.org/abs/1903.03129)]
    - Beidi Chen, Tharun Medini, James Farwell, Sameh Gobriel, Charlie Tai, Anshumali Shrivastava

- Learning Adversarial Networks for Semi-Supervised Text Classification via Policy Gradient (2018) [[Summary](./summaries/adversarial-networks-policy-gradient.pdf)] [[Paper](https://dl.acm.org/doi/10.1145/3219819.3219956)]
    -  Yan Li, Jieping Ye

- Tensor Networks in a Nutshell (2017) [[Summary](./summaries/tensor-network.pdf)] [[Paper](https://arxiv.org/abs/1708.00006)]
    - Jacob Biamonte, Ville Bergholm

- Zero-shot Knowledge Transfer via Adversarial Belief Matching (2019) [[Summary](./summaries/zero-shot-knowledge-transfer.pdf)][[Paper](https://arxiv.org/abs/1905.09768)]
    - Paul Micaelli, Amos Storkey

- Patient Knowledge Distillation for BERT Model Compression (2019) [[Summary](./summaries/patient-knowledge-distillation.pdf)] [[Paper](https://arxiv.org/abs/1908.09355)]
    - Siqi Sun, Yu Cheng, Zhe Gan, Jingjing Liu

- Reformer: The Efficient Transformer (2020) [[Review](./summaries/reformer-the-efficient-transformer.pdf)][[Paper](https://arxiv.org/abs/2001.04451)]
    - Nikita Kitaev, Łukasz Kaiser, Anselm Levskaya

- Legendre Memory Units: Continuous-Time
Representation in Recurrent Neural Networks (2019) [[Summary](./summaries/legendre-memory-units.pdf)][[Paper](https://papers.nips.cc/paper/9689-legendre-memory-units-continuous-time-representation-in-recurrent-neural-networks.pdf)]
    - Aaron R. Voelker, Ivana Kajic, Chris Eliasmith

## 2019 

- Input-Cell Attention Reduces Vanishing Saliency of Recurrent Neural Networks (2019) [[Review](./summaries/input-cell-attention.pdf)][[Paper](https://arxiv.org/abs/1910.12370)]
    - Aya Abdelsalam Ismail, Mohamed Gunady, Luiz Pessoa, Héctor Corrada Bravo, Soheil Feizi

- Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (2019) [[Summary](./summaries/text-to-text-transfer-transformer.pdf)][[Paper](https://arxiv.org/abs/1910.10683)]
    - Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu

- Single Headed Attention RNN: Stop Thinking With Your Head (2019) [[Summary](./summaries/single-headed-attention-rnn.pdf)] [[Paper](https://arxiv.org/abs/1911.11423)]
    - Stephen Merity

- Attention is all you need (2019) [[Summary](./summaries/attention-is-all-you-need.pdf)][[Paper](https://arxiv.org/abs/1706.03762)]
    - Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin
